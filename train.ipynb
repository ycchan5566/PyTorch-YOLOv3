{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=7, checkpoint_dir='/tmp/work', checkpoint_interval=10, class_path='/home/dllab/final/clothes.names', conf_thres=0.8, data_config_path='/home/dllab/final/clothes.data', epochs=121, image_folder='data/samples', img_size=416, model_config_path='/home/dllab/final/yolov3.cfg', n_cpu=0, nms_thres=0.4, use_cuda=True, weights_path='/tmp/work/105.pt')\n",
      "[Epoch 0/121, Batch 0/143] [Losses: x 0.014281, y 0.015409, w 0.024643, h 0.023405, conf 0.048614, cls 0.672135, total 0.798488, recall: 0.56863, precision: 0.09254]\n",
      "[Epoch 0/121, Batch 1/143] [Losses: x 0.018559, y 0.019965, w 0.031780, h 0.022340, conf 0.070540, cls 0.633701, total 0.796885, recall: 0.62500, precision: 0.10704]\n",
      "[Epoch 0/121, Batch 2/143] [Losses: x 0.014751, y 0.013127, w 0.031286, h 0.027017, conf 0.048986, cls 0.621724, total 0.756892, recall: 0.64286, precision: 0.08332]\n",
      "[Epoch 0/121, Batch 3/143] [Losses: x 0.021709, y 0.025441, w 0.030546, h 0.020780, conf 0.060347, cls 0.622029, total 0.780852, recall: 0.72000, precision: 0.15586]\n",
      "[Epoch 0/121, Batch 4/143] [Losses: x 0.027938, y 0.017488, w 0.030132, h 0.032647, conf 0.076641, cls 0.634347, total 0.819193, recall: 0.62821, precision: 0.12100]\n",
      "[Epoch 0/121, Batch 5/143] [Losses: x 0.030760, y 0.016565, w 0.038528, h 0.020007, conf 0.059190, cls 0.613451, total 0.778501, recall: 0.64912, precision: 0.09236]\n",
      "[Epoch 0/121, Batch 6/143] [Losses: x 0.031994, y 0.030572, w 0.026622, h 0.029352, conf 0.061071, cls 0.638674, total 0.818286, recall: 0.68254, precision: 0.11059]\n",
      "[Epoch 0/121, Batch 7/143] [Losses: x 0.021608, y 0.013524, w 0.024905, h 0.036939, conf 0.053092, cls 0.643262, total 0.793331, recall: 0.56410, precision: 0.07257]\n",
      "[Epoch 0/121, Batch 8/143] [Losses: x 0.031874, y 0.019099, w 0.041229, h 0.031875, conf 0.080200, cls 0.637249, total 0.841527, recall: 0.62500, precision: 0.11169]\n",
      "[Epoch 0/121, Batch 9/143] [Losses: x 0.023637, y 0.017322, w 0.021888, h 0.028013, conf 0.053229, cls 0.703763, total 0.847852, recall: 0.42222, precision: 0.06160]\n",
      "[Epoch 0/121, Batch 10/143] [Losses: x 0.023341, y 0.034306, w 0.033370, h 0.043867, conf 0.097416, cls 0.655583, total 0.887884, recall: 0.62667, precision: 0.10798]\n",
      "[Epoch 0/121, Batch 11/143] [Losses: x 0.015485, y 0.023074, w 0.045128, h 0.037816, conf 0.069508, cls 0.632693, total 0.823703, recall: 0.60000, precision: 0.06280]\n",
      "[Epoch 0/121, Batch 12/143] [Losses: x 0.040110, y 0.030030, w 0.037432, h 0.032623, conf 0.071823, cls 0.620160, total 0.832178, recall: 0.63768, precision: 0.11015]\n",
      "[Epoch 0/121, Batch 13/143] [Losses: x 0.026639, y 0.030108, w 0.029801, h 0.028996, conf 0.062493, cls 0.590337, total 0.768375, recall: 0.82051, precision: 0.07757]\n",
      "[Epoch 0/121, Batch 14/143] [Losses: x 0.021904, y 0.026500, w 0.034809, h 0.034333, conf 0.059476, cls 0.633713, total 0.810734, recall: 0.58333, precision: 0.08138]\n",
      "[Epoch 0/121, Batch 15/143] [Losses: x 0.030124, y 0.021347, w 0.033116, h 0.019340, conf 0.069140, cls 0.644094, total 0.817160, recall: 0.59259, precision: 0.07465]\n",
      "[Epoch 0/121, Batch 16/143] [Losses: x 0.028049, y 0.024147, w 0.031431, h 0.018318, conf 0.070168, cls 0.642951, total 0.815064, recall: 0.53333, precision: 0.07891]\n",
      "[Epoch 0/121, Batch 17/143] [Losses: x 0.026426, y 0.041665, w 0.049141, h 0.031903, conf 0.075314, cls 0.639751, total 0.864202, recall: 0.72464, precision: 0.13008]\n",
      "[Epoch 0/121, Batch 18/143] [Losses: x 0.026149, y 0.020481, w 0.052876, h 0.030313, conf 0.065270, cls 0.621524, total 0.816613, recall: 0.68519, precision: 0.09386]\n",
      "[Epoch 0/121, Batch 19/143] [Losses: x 0.033722, y 0.038826, w 0.029533, h 0.021159, conf 0.078045, cls 0.611406, total 0.812691, recall: 0.69697, precision: 0.11354]\n",
      "[Epoch 0/121, Batch 20/143] [Losses: x 0.021216, y 0.032427, w 0.053904, h 0.031960, conf 0.098535, cls 0.599620, total 0.837663, recall: 0.74359, precision: 0.09017]\n",
      "[Epoch 0/121, Batch 21/143] [Losses: x 0.039329, y 0.040465, w 0.051809, h 0.052096, conf 0.114058, cls 0.643418, total 0.941175, recall: 0.63964, precision: 0.13315]\n",
      "[Epoch 0/121, Batch 22/143] [Losses: x 0.022714, y 0.032267, w 0.050141, h 0.034012, conf 0.063135, cls 0.617455, total 0.819723, recall: 0.77778, precision: 0.13101]\n",
      "[Epoch 0/121, Batch 23/143] [Losses: x 0.024661, y 0.024825, w 0.018947, h 0.024795, conf 0.056886, cls 0.625729, total 0.775844, recall: 0.69231, precision: 0.07308]\n",
      "[Epoch 0/121, Batch 24/143] [Losses: x 0.020162, y 0.028055, w 0.035319, h 0.021294, conf 0.070510, cls 0.598953, total 0.774293, recall: 0.75000, precision: 0.06058]\n",
      "[Epoch 0/121, Batch 25/143] [Losses: x 0.035188, y 0.037238, w 0.038928, h 0.030332, conf 0.063459, cls 0.639534, total 0.844679, recall: 0.68421, precision: 0.09855]\n",
      "[Epoch 0/121, Batch 26/143] [Losses: x 0.041316, y 0.041907, w 0.026062, h 0.035355, conf 0.058024, cls 0.621187, total 0.823851, recall: 0.66667, precision: 0.07740]\n",
      "[Epoch 0/121, Batch 27/143] [Losses: x 0.037422, y 0.042056, w 0.063049, h 0.045542, conf 0.103235, cls 0.636423, total 0.927727, recall: 0.61905, precision: 0.11725]\n",
      "[Epoch 0/121, Batch 28/143] [Losses: x 0.031290, y 0.031518, w 0.031167, h 0.029757, conf 0.076296, cls 0.629260, total 0.829288, recall: 0.58333, precision: 0.07697]\n",
      "[Epoch 0/121, Batch 29/143] [Losses: x 0.037042, y 0.030606, w 0.041885, h 0.036922, conf 0.088100, cls 0.663473, total 0.898029, recall: 0.59259, precision: 0.10340]\n",
      "[Epoch 0/121, Batch 30/143] [Losses: x 0.015979, y 0.016414, w 0.035321, h 0.022194, conf 0.054282, cls 0.622747, total 0.766936, recall: 0.80952, precision: 0.10635]\n",
      "[Epoch 0/121, Batch 31/143] [Losses: x 0.039583, y 0.048925, w 0.031447, h 0.033733, conf 0.077386, cls 0.631303, total 0.862377, recall: 0.60000, precision: 0.08703]\n",
      "[Epoch 0/121, Batch 32/143] [Losses: x 0.029899, y 0.044932, w 0.041086, h 0.036682, conf 0.063312, cls 0.620964, total 0.836875, recall: 0.66667, precision: 0.09686]\n",
      "[Epoch 0/121, Batch 33/143] [Losses: x 0.041788, y 0.040816, w 0.043307, h 0.044104, conf 0.102078, cls 0.635251, total 0.907343, recall: 0.72727, precision: 0.12502]\n",
      "[Epoch 0/121, Batch 34/143] [Losses: x 0.020981, y 0.030583, w 0.052281, h 0.035688, conf 0.060033, cls 0.641083, total 0.840648, recall: 0.59649, precision: 0.08703]\n",
      "[Epoch 0/121, Batch 35/143] [Losses: x 0.038572, y 0.038966, w 0.054706, h 0.043409, conf 0.083632, cls 0.632973, total 0.892257, recall: 0.69048, precision: 0.10620]\n",
      "[Epoch 0/121, Batch 36/143] [Losses: x 0.031109, y 0.043320, w 0.048594, h 0.038733, conf 0.135997, cls 0.605174, total 0.902927, recall: 0.65333, precision: 0.09431]\n",
      "[Epoch 0/121, Batch 37/143] [Losses: x 0.024850, y 0.047019, w 0.038803, h 0.022858, conf 0.079357, cls 0.630456, total 0.843344, recall: 0.65152, precision: 0.07646]\n",
      "[Epoch 0/121, Batch 38/143] [Losses: x 0.034041, y 0.032166, w 0.047926, h 0.051178, conf 0.088954, cls 0.652912, total 0.907177, recall: 0.55556, precision: 0.07836]\n",
      "[Epoch 0/121, Batch 39/143] [Losses: x 0.035008, y 0.039750, w 0.048773, h 0.053147, conf 0.090637, cls 0.652026, total 0.919342, recall: 0.57576, precision: 0.09715]\n",
      "[Epoch 0/121, Batch 40/143] [Losses: x 0.043265, y 0.030602, w 0.063139, h 0.043215, conf 0.108258, cls 0.636740, total 0.925218, recall: 0.71605, precision: 0.12647]\n",
      "[Epoch 0/121, Batch 41/143] [Losses: x 0.063756, y 0.042391, w 0.045077, h 0.039770, conf 0.131992, cls 0.656266, total 0.979251, recall: 0.53846, precision: 0.11800]\n",
      "[Epoch 0/121, Batch 42/143] [Losses: x 0.016766, y 0.029929, w 0.023423, h 0.035803, conf 0.061615, cls 0.600327, total 0.767861, recall: 0.62222, precision: 0.07207]\n",
      "[Epoch 0/121, Batch 43/143] [Losses: x 0.029804, y 0.020823, w 0.045466, h 0.027780, conf 0.077973, cls 0.614479, total 0.816325, recall: 0.79630, precision: 0.09596]\n",
      "[Epoch 0/121, Batch 44/143] [Losses: x 0.025144, y 0.025775, w 0.033325, h 0.026312, conf 0.065151, cls 0.628066, total 0.803774, recall: 0.64583, precision: 0.06842]\n",
      "[Epoch 0/121, Batch 45/143] [Losses: x 0.030243, y 0.031151, w 0.044249, h 0.039642, conf 0.089182, cls 0.657775, total 0.892241, recall: 0.56944, precision: 0.07393]\n",
      "[Epoch 0/121, Batch 46/143] [Losses: x 0.041202, y 0.033395, w 0.040959, h 0.042576, conf 0.108917, cls 0.640402, total 0.907451, recall: 0.67708, precision: 0.09865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/121, Batch 47/143] [Losses: x 0.030118, y 0.019067, w 0.049393, h 0.037155, conf 0.062198, cls 0.658855, total 0.856785, recall: 0.66667, precision: 0.11164]\n",
      "[Epoch 0/121, Batch 48/143] [Losses: x 0.030651, y 0.026126, w 0.030972, h 0.022142, conf 0.087156, cls 0.640494, total 0.837542, recall: 0.69048, precision: 0.05778]\n",
      "[Epoch 0/121, Batch 49/143] [Losses: x 0.028313, y 0.026125, w 0.029839, h 0.026666, conf 0.074636, cls 0.627170, total 0.812749, recall: 0.50877, precision: 0.06467]\n",
      "[Epoch 0/121, Batch 50/143] [Losses: x 0.043153, y 0.017618, w 0.027892, h 0.020950, conf 0.068079, cls 0.612771, total 0.790463, recall: 0.68889, precision: 0.07916]\n",
      "[Epoch 0/121, Batch 51/143] [Losses: x 0.031128, y 0.018071, w 0.040535, h 0.032863, conf 0.094213, cls 0.598829, total 0.815640, recall: 0.66667, precision: 0.06881]\n",
      "[Epoch 0/121, Batch 52/143] [Losses: x 0.023762, y 0.024436, w 0.048345, h 0.037653, conf 0.092927, cls 0.639268, total 0.866391, recall: 0.59649, precision: 0.06863]\n",
      "[Epoch 0/121, Batch 53/143] [Losses: x 0.024087, y 0.027686, w 0.050936, h 0.033425, conf 0.075928, cls 0.632862, total 0.844923, recall: 0.64706, precision: 0.07168]\n",
      "[Epoch 0/121, Batch 54/143] [Losses: x 0.036719, y 0.048099, w 0.029063, h 0.036940, conf 0.142450, cls 0.633018, total 0.926289, recall: 0.66667, precision: 0.08805]\n",
      "[Epoch 0/121, Batch 55/143] [Losses: x 0.028228, y 0.025287, w 0.023922, h 0.026405, conf 0.154229, cls 0.632970, total 0.891041, recall: 0.61905, precision: 0.06715]\n",
      "[Epoch 0/121, Batch 56/143] [Losses: x 0.030296, y 0.028299, w 0.057726, h 0.034955, conf 0.148898, cls 0.673069, total 0.973244, recall: 0.58333, precision: 0.09634]\n",
      "[Epoch 0/121, Batch 57/143] [Losses: x 0.027502, y 0.026543, w 0.046207, h 0.060744, conf 0.092122, cls 0.610849, total 0.863967, recall: 0.74359, precision: 0.06375]\n",
      "[Epoch 0/121, Batch 58/143] [Losses: x 0.041450, y 0.066389, w 0.042237, h 0.046980, conf 0.169900, cls 0.659321, total 1.026277, recall: 0.57471, precision: 0.07252]\n",
      "[Epoch 0/121, Batch 59/143] [Losses: x 0.051733, y 0.037551, w 0.040700, h 0.035695, conf 0.113517, cls 0.615167, total 0.894362, recall: 0.68750, precision: 0.06137]\n",
      "[Epoch 0/121, Batch 60/143] [Losses: x 0.063553, y 0.044053, w 0.051654, h 0.040426, conf 0.111928, cls 0.624895, total 0.936508, recall: 0.61905, precision: 0.05621]\n",
      "[Epoch 0/121, Batch 61/143] [Losses: x 0.037715, y 0.031004, w 0.054381, h 0.057068, conf 0.116736, cls 0.608449, total 0.905353, recall: 0.76471, precision: 0.07221]\n",
      "[Epoch 0/121, Batch 62/143] [Losses: x 0.032610, y 0.026014, w 0.050038, h 0.051043, conf 0.106202, cls 0.639500, total 0.905407, recall: 0.62500, precision: 0.05273]\n",
      "[Epoch 0/121, Batch 63/143] [Losses: x 0.041268, y 0.049284, w 0.041604, h 0.034017, conf 0.103209, cls 0.630538, total 0.899921, recall: 0.72549, precision: 0.07156]\n",
      "[Epoch 0/121, Batch 64/143] [Losses: x 0.027296, y 0.041423, w 0.067002, h 0.039988, conf 0.089397, cls 0.619550, total 0.884655, recall: 0.73333, precision: 0.06290]\n",
      "[Epoch 0/121, Batch 65/143] [Losses: x 0.033581, y 0.046754, w 0.034957, h 0.017458, conf 0.087920, cls 0.620370, total 0.841041, recall: 0.69048, precision: 0.06809]\n",
      "[Epoch 0/121, Batch 66/143] [Losses: x 0.078341, y 0.049793, w 0.053204, h 0.034411, conf 0.151142, cls 0.663528, total 1.030421, recall: 0.66667, precision: 0.07554]\n",
      "[Epoch 0/121, Batch 67/143] [Losses: x 0.049073, y 0.057176, w 0.053596, h 0.040771, conf 0.112686, cls 0.616514, total 0.929817, recall: 0.79630, precision: 0.07418]\n",
      "[Epoch 0/121, Batch 68/143] [Losses: x 0.082517, y 0.041442, w 0.071263, h 0.028693, conf 0.094674, cls 0.614717, total 0.933306, recall: 0.70175, precision: 0.07945]\n",
      "[Epoch 0/121, Batch 69/143] [Losses: x 0.047158, y 0.046744, w 0.067229, h 0.025981, conf 0.101582, cls 0.645755, total 0.934450, recall: 0.69444, precision: 0.04537]\n",
      "[Epoch 0/121, Batch 70/143] [Losses: x 0.048524, y 0.042153, w 0.063580, h 0.038045, conf 0.119701, cls 0.644264, total 0.956267, recall: 0.62500, precision: 0.07770]\n",
      "[Epoch 0/121, Batch 71/143] [Losses: x 0.042040, y 0.038250, w 0.056946, h 0.027069, conf 0.112718, cls 0.651409, total 0.928432, recall: 0.59722, precision: 0.05560]\n",
      "[Epoch 0/121, Batch 72/143] [Losses: x 0.022678, y 0.034650, w 0.058985, h 0.031111, conf 0.091885, cls 0.645853, total 0.885163, recall: 0.56410, precision: 0.04249]\n",
      "[Epoch 0/121, Batch 73/143] [Losses: x 0.036419, y 0.038673, w 0.033995, h 0.030820, conf 0.099769, cls 0.659420, total 0.899096, recall: 0.59259, precision: 0.05738]\n",
      "[Epoch 0/121, Batch 74/143] [Losses: x 0.039897, y 0.042063, w 0.044938, h 0.037084, conf 0.127818, cls 0.601878, total 0.893679, recall: 0.66667, precision: 0.06052]\n",
      "[Epoch 0/121, Batch 75/143] [Losses: x 0.039040, y 0.054974, w 0.035686, h 0.019781, conf 0.072983, cls 0.658210, total 0.880674, recall: 0.55556, precision: 0.03921]\n",
      "[Epoch 0/121, Batch 76/143] [Losses: x 0.041061, y 0.028845, w 0.043309, h 0.047811, conf 0.090894, cls 0.653857, total 0.905777, recall: 0.58974, precision: 0.04170]\n",
      "[Epoch 0/121, Batch 77/143] [Losses: x 0.057394, y 0.042120, w 0.068355, h 0.063700, conf 0.138802, cls 0.618757, total 0.989128, recall: 0.58974, precision: 0.04088]\n",
      "[Epoch 0/121, Batch 78/143] [Losses: x 0.051849, y 0.037373, w 0.060021, h 0.051078, conf 0.087882, cls 0.656588, total 0.944790, recall: 0.56061, precision: 0.05957]\n",
      "[Epoch 0/121, Batch 79/143] [Losses: x 0.029459, y 0.051115, w 0.055472, h 0.014112, conf 0.073438, cls 0.666641, total 0.890237, recall: 0.68889, precision: 0.05902]\n",
      "[Epoch 0/121, Batch 80/143] [Losses: x 0.043483, y 0.027828, w 0.034450, h 0.019529, conf 0.080098, cls 0.623234, total 0.828622, recall: 0.62500, precision: 0.05310]\n",
      "[Epoch 0/121, Batch 81/143] [Losses: x 0.067954, y 0.051630, w 0.056148, h 0.051344, conf 0.107206, cls 0.641251, total 0.975533, recall: 0.55914, precision: 0.08937]\n",
      "[Epoch 0/121, Batch 82/143] [Losses: x 0.056189, y 0.032277, w 0.059152, h 0.052363, conf 0.156882, cls 0.679192, total 1.036056, recall: 0.59770, precision: 0.08760]\n",
      "[Epoch 0/121, Batch 83/143] [Losses: x 0.050720, y 0.068874, w 0.060033, h 0.065934, conf 0.340306, cls 0.691987, total 1.277855, recall: 0.59804, precision: 0.08658]\n",
      "[Epoch 0/121, Batch 84/143] [Losses: x 0.034128, y 0.041955, w 0.043540, h 0.049482, conf 0.558123, cls 0.628272, total 1.355500, recall: 0.61404, precision: 0.07453]\n",
      "[Epoch 0/121, Batch 85/143] [Losses: x 0.041438, y 0.039196, w 0.045860, h 0.029539, conf 0.101255, cls 0.607975, total 0.865263, recall: 0.78788, precision: 0.09485]\n",
      "[Epoch 0/121, Batch 86/143] [Losses: x 0.047340, y 0.044970, w 0.076103, h 0.047651, conf 0.113254, cls 0.648220, total 0.977538, recall: 0.58586, precision: 0.06575]\n",
      "[Epoch 0/121, Batch 87/143] [Losses: x 0.052727, y 0.046972, w 0.058376, h 0.037271, conf 0.135953, cls 0.620896, total 0.952195, recall: 0.66667, precision: 0.06689]\n",
      "[Epoch 0/121, Batch 88/143] [Losses: x 0.038489, y 0.048526, w 0.043541, h 0.030583, conf 0.097510, cls 0.628005, total 0.886654, recall: 0.63158, precision: 0.05753]\n",
      "[Epoch 0/121, Batch 89/143] [Losses: x 0.056857, y 0.061796, w 0.034978, h 0.060042, conf 0.126620, cls 0.636910, total 0.977203, recall: 0.66667, precision: 0.07126]\n",
      "[Epoch 0/121, Batch 90/143] [Losses: x 0.049380, y 0.054901, w 0.053588, h 0.040982, conf 0.169902, cls 0.658615, total 1.027368, recall: 0.61905, precision: 0.07639]\n",
      "[Epoch 0/121, Batch 91/143] [Losses: x 0.047192, y 0.057819, w 0.064438, h 0.069858, conf 0.156628, cls 0.646761, total 1.042696, recall: 0.70370, precision: 0.07519]\n",
      "[Epoch 0/121, Batch 92/143] [Losses: x 0.034255, y 0.041636, w 0.042959, h 0.047534, conf 0.488930, cls 0.621690, total 1.277004, recall: 0.51282, precision: 0.03720]\n",
      "[Epoch 0/121, Batch 93/143] [Losses: x 0.051050, y 0.034460, w 0.048707, h 0.058515, conf 0.159823, cls 0.627514, total 0.980068, recall: 0.57576, precision: 0.04292]\n",
      "[Epoch 0/121, Batch 94/143] [Losses: x 0.039338, y 0.038746, w 0.058538, h 0.028978, conf 0.124918, cls 0.618288, total 0.908806, recall: 0.64103, precision: 0.03832]\n",
      "[Epoch 0/121, Batch 95/143] [Losses: x 0.044598, y 0.058207, w 0.064198, h 0.035013, conf 0.193431, cls 0.672699, total 1.068145, recall: 0.59804, precision: 0.07151]\n",
      "[Epoch 0/121, Batch 96/143] [Losses: x 0.024054, y 0.041532, w 0.070453, h 0.039578, conf 0.146787, cls 0.623279, total 0.945682, recall: 0.64286, precision: 0.04338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/121, Batch 97/143] [Losses: x 0.041444, y 0.054758, w 0.042675, h 0.056230, conf 0.286426, cls 0.621729, total 1.103261, recall: 0.74603, precision: 0.06752]\n",
      "[Epoch 0/121, Batch 98/143] [Losses: x 0.038033, y 0.034024, w 0.078454, h 0.076916, conf 0.131717, cls 0.646031, total 1.005174, recall: 0.61111, precision: 0.04084]\n",
      "[Epoch 0/121, Batch 99/143] [Losses: x 0.040324, y 0.045399, w 0.051493, h 0.055233, conf 0.143938, cls 0.628254, total 0.964642, recall: 0.56410, precision: 0.02970]\n",
      "[Epoch 0/121, Batch 100/143] [Losses: x 0.032607, y 0.046301, w 0.025297, h 0.029801, conf 0.168439, cls 0.638666, total 0.941111, recall: 0.49206, precision: 0.04077]\n",
      "[Epoch 0/121, Batch 101/143] [Losses: x 0.044885, y 0.044856, w 0.077526, h 0.076738, conf 0.172174, cls 0.649656, total 1.065836, recall: 0.60494, precision: 0.05595]\n",
      "[Epoch 0/121, Batch 102/143] [Losses: x 0.093089, y 0.075363, w 0.085669, h 0.025402, conf 0.186187, cls 0.680332, total 1.146043, recall: 0.56667, precision: 0.03887]\n",
      "[Epoch 0/121, Batch 103/143] [Losses: x 0.061689, y 0.050524, w 0.083765, h 0.032890, conf 0.135978, cls 0.641085, total 1.005930, recall: 0.64583, precision: 0.04239]\n",
      "[Epoch 0/121, Batch 104/143] [Losses: x 0.042974, y 0.039746, w 0.071621, h 0.038156, conf 0.134081, cls 0.620291, total 0.946870, recall: 0.66667, precision: 0.03164]\n",
      "[Epoch 0/121, Batch 105/143] [Losses: x 0.052287, y 0.053341, w 0.047489, h 0.024756, conf 0.136669, cls 0.638999, total 0.953542, recall: 0.57143, precision: 0.02901]\n",
      "[Epoch 0/121, Batch 106/143] [Losses: x 0.046699, y 0.041458, w 0.086577, h 0.032274, conf 0.339325, cls 0.641566, total 1.187900, recall: 0.55556, precision: 0.03565]\n",
      "[Epoch 0/121, Batch 107/143] [Losses: x 0.047903, y 0.106045, w 0.091901, h 0.041579, conf 0.280047, cls 0.661165, total 1.228639, recall: 0.57407, precision: 0.04231]\n",
      "[Epoch 0/121, Batch 108/143] [Losses: x 0.059833, y 0.073227, w 0.057796, h 0.060897, conf 0.189065, cls 0.714731, total 1.155548, recall: 0.46914, precision: 0.04804]\n",
      "[Epoch 0/121, Batch 109/143] [Losses: x 0.052450, y 0.035700, w 0.070757, h 0.065231, conf 0.198722, cls 0.658914, total 1.081775, recall: 0.52778, precision: 0.04450]\n",
      "[Epoch 0/121, Batch 110/143] [Losses: x 0.030779, y 0.054799, w 0.057503, h 0.035371, conf 0.219014, cls 0.645934, total 1.043401, recall: 0.60000, precision: 0.04348]\n",
      "[Epoch 0/121, Batch 111/143] [Losses: x 0.036720, y 0.067591, w 0.037136, h 0.054224, conf 0.160408, cls 0.643470, total 0.999548, recall: 0.64815, precision: 0.03350]\n",
      "[Epoch 0/121, Batch 112/143] [Losses: x 0.059696, y 0.052284, w 0.064914, h 0.038629, conf 0.260546, cls 0.642395, total 1.118464, recall: 0.66667, precision: 0.03710]\n",
      "[Epoch 0/121, Batch 113/143] [Losses: x 0.049960, y 0.050117, w 0.079330, h 0.042177, conf 0.263728, cls 0.641708, total 1.127019, recall: 0.66667, precision: 0.03691]\n",
      "[Epoch 0/121, Batch 114/143] [Losses: x 0.047232, y 0.055730, w 0.065359, h 0.063019, conf 0.176949, cls 0.666470, total 1.074760, recall: 0.57895, precision: 0.04903]\n",
      "[Epoch 0/121, Batch 115/143] [Losses: x 0.033887, y 0.049856, w 0.069520, h 0.038999, conf 0.169369, cls 0.658963, total 1.020593, recall: 0.56250, precision: 0.03440]\n",
      "[Epoch 0/121, Batch 116/143] [Losses: x 0.049177, y 0.059823, w 0.094956, h 0.090501, conf 0.172002, cls 0.684053, total 1.150513, recall: 0.63889, precision: 0.05439]\n",
      "[Epoch 0/121, Batch 117/143] [Losses: x 0.063545, y 0.060843, w 0.073340, h 0.058068, conf 0.244828, cls 0.664508, total 1.165131, recall: 0.53623, precision: 0.03865]\n",
      "[Epoch 0/121, Batch 118/143] [Losses: x 0.066493, y 0.079205, w 0.101993, h 0.052668, conf 0.308078, cls 0.711094, total 1.319530, recall: 0.53763, precision: 0.04084]\n",
      "[Epoch 0/121, Batch 119/143] [Losses: x 0.107113, y 0.038924, w 0.073551, h 0.039000, conf 0.153692, cls 0.655805, total 1.068084, recall: 0.60000, precision: 0.03333]\n",
      "[Epoch 0/121, Batch 120/143] [Losses: x 0.057883, y 0.082571, w 0.074967, h 0.039115, conf 0.195762, cls 0.614980, total 1.065278, recall: 0.75556, precision: 0.04276]\n",
      "[Epoch 0/121, Batch 121/143] [Losses: x 0.070971, y 0.060600, w 0.060337, h 0.055085, conf 0.246551, cls 0.637687, total 1.131231, recall: 0.57692, precision: 0.04108]\n",
      "[Epoch 0/121, Batch 122/143] [Losses: x 0.041125, y 0.031626, w 0.050814, h 0.088707, conf 0.220779, cls 0.625253, total 1.058304, recall: 0.69444, precision: 0.02324]\n",
      "[Epoch 0/121, Batch 123/143] [Losses: x 0.057879, y 0.053328, w 0.062171, h 0.036205, conf 0.207403, cls 0.644904, total 1.061890, recall: 0.53030, precision: 0.03072]\n",
      "[Epoch 0/121, Batch 124/143] [Losses: x 0.041430, y 0.046824, w 0.052604, h 0.035225, conf 0.179017, cls 0.619275, total 0.974374, recall: 0.61905, precision: 0.02787]\n",
      "[Epoch 0/121, Batch 125/143] [Losses: x 0.048221, y 0.055021, w 0.087665, h 0.044265, conf 0.412066, cls 0.662612, total 1.309849, recall: 0.62500, precision: 0.03699]\n",
      "[Epoch 0/121, Batch 126/143] [Losses: x 0.041631, y 0.052517, w 0.060772, h 0.034569, conf 0.153903, cls 0.653769, total 0.997161, recall: 0.61905, precision: 0.04120]\n",
      "[Epoch 0/121, Batch 127/143] [Losses: x 0.043276, y 0.071963, w 0.055812, h 0.038789, conf 0.171149, cls 0.645255, total 1.026244, recall: 0.71429, precision: 0.02953]\n",
      "[Epoch 0/121, Batch 128/143] [Losses: x 0.065068, y 0.048826, w 0.104201, h 0.044096, conf 0.201101, cls 0.685365, total 1.148657, recall: 0.42308, precision: 0.02986]\n",
      "[Epoch 0/121, Batch 129/143] [Losses: x 0.073697, y 0.084599, w 0.094260, h 0.105341, conf 0.282449, cls 0.709974, total 1.350320, recall: 0.38889, precision: 0.03467]\n",
      "[Epoch 0/121, Batch 130/143] [Losses: x 0.066474, y 0.049768, w 0.104848, h 0.054849, conf 0.175642, cls 0.650511, total 1.102093, recall: 0.64444, precision: 0.02988]\n",
      "[Epoch 0/121, Batch 131/143] [Losses: x 0.046752, y 0.064112, w 0.090036, h 0.052875, conf 0.158593, cls 0.643105, total 1.055473, recall: 0.70370, precision: 0.03993]\n",
      "[Epoch 0/121, Batch 132/143] [Losses: x 0.046676, y 0.056008, w 0.066788, h 0.081810, conf 0.374437, cls 0.619357, total 1.245075, recall: 0.59722, precision: 0.03699]\n",
      "[Epoch 0/121, Batch 133/143] [Losses: x 0.052351, y 0.059280, w 0.058954, h 0.045867, conf 0.188152, cls 0.660355, total 1.064959, recall: 0.66667, precision: 0.04791]\n",
      "[Epoch 0/121, Batch 134/143] [Losses: x 0.068281, y 0.062338, w 0.088039, h 0.051701, conf 0.209621, cls 0.654246, total 1.134226, recall: 0.62963, precision: 0.04394]\n",
      "[Epoch 0/121, Batch 135/143] [Losses: x 0.066496, y 0.085850, w 0.048160, h 0.108286, conf 0.156125, cls 0.651189, total 1.116106, recall: 0.62222, precision: 0.03604]\n",
      "[Epoch 0/121, Batch 136/143] [Losses: x 0.060090, y 0.079742, w 0.068538, h 0.067413, conf 0.225030, cls 0.660968, total 1.161781, recall: 0.55072, precision: 0.03910]\n",
      "[Epoch 0/121, Batch 137/143] [Losses: x 0.047157, y 0.041335, w 0.067012, h 0.076792, conf 0.185391, cls 0.639980, total 1.057667, recall: 0.70175, precision: 0.04066]\n",
      "[Epoch 0/121, Batch 138/143] [Losses: x 0.038572, y 0.057461, w 0.078788, h 0.123319, conf 0.189363, cls 0.648952, total 1.136455, recall: 0.66667, precision: 0.04471]\n",
      "[Epoch 0/121, Batch 139/143] [Losses: x 0.054903, y 0.060803, w 0.078537, h 0.086841, conf 0.234438, cls 0.655792, total 1.171313, recall: 0.65278, precision: 0.04204]\n",
      "[Epoch 0/121, Batch 140/143] [Losses: x 0.068886, y 0.066786, w 0.079034, h 0.045269, conf 0.294070, cls 0.639843, total 1.193888, recall: 0.66667, precision: 0.05651]\n",
      "[Epoch 0/121, Batch 141/143] [Losses: x 0.040191, y 0.072719, w 0.085662, h 0.060022, conf 0.141731, cls 0.634646, total 1.034971, recall: 0.68182, precision: 0.04619]\n",
      "[Epoch 0/121, Batch 142/143] [Losses: x 0.029704, y 0.036592, w 0.036651, h 0.024470, conf 0.115694, cls 1.346422, total 1.589532, recall: 0.85714, precision: 0.05191]\n",
      "[Epoch 1/121, Batch 0/143] [Losses: x 0.054966, y 0.089029, w 0.062276, h 0.093536, conf 0.153443, cls 0.685701, total 1.138951, recall: 0.58824, precision: 0.03659]\n",
      "[Epoch 1/121, Batch 1/143] [Losses: x 0.062964, y 0.066533, w 0.054623, h 0.086117, conf 0.157756, cls 0.642185, total 1.070178, recall: 0.63889, precision: 0.04431]\n",
      "[Epoch 1/121, Batch 2/143] [Losses: x 0.057570, y 0.069180, w 0.087418, h 0.087311, conf 0.135384, cls 0.634356, total 1.071219, recall: 0.50000, precision: 0.02484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/121, Batch 3/143] [Losses: x 0.051740, y 0.060387, w 0.059585, h 0.057849, conf 0.154362, cls 0.644094, total 1.028016, recall: 0.65333, precision: 0.05400]\n",
      "[Epoch 1/121, Batch 4/143] [Losses: x 0.063017, y 0.042574, w 0.073742, h 0.056017, conf 0.308381, cls 0.640639, total 1.184370, recall: 0.56410, precision: 0.05208]\n",
      "[Epoch 1/121, Batch 5/143] [Losses: x 0.056347, y 0.130140, w 0.052375, h 0.078749, conf 0.151760, cls 0.622933, total 1.092304, recall: 0.64912, precision: 0.05311]\n",
      "[Epoch 1/121, Batch 6/143] [Losses: x 0.073266, y 0.061417, w 0.048525, h 0.046866, conf 0.134518, cls 0.650725, total 1.015317, recall: 0.61905, precision: 0.04853]\n",
      "[Epoch 1/121, Batch 7/143] [Losses: x 0.056309, y 0.047255, w 0.047103, h 0.056750, conf 0.143034, cls 0.657266, total 1.007716, recall: 0.56410, precision: 0.03139]\n",
      "[Epoch 1/121, Batch 8/143] [Losses: x 0.058009, y 0.089728, w 0.082148, h 0.065360, conf 0.163639, cls 0.649536, total 1.108420, recall: 0.63889, precision: 0.05578]\n",
      "[Epoch 1/121, Batch 9/143] [Losses: x 0.040570, y 0.044179, w 0.084194, h 0.043997, conf 0.196415, cls 0.721009, total 1.130363, recall: 0.42222, precision: 0.02417]\n",
      "[Epoch 1/121, Batch 10/143] [Losses: x 0.051484, y 0.075490, w 0.074252, h 0.049050, conf 0.162822, cls 0.662272, total 1.075370, recall: 0.62667, precision: 0.05702]\n",
      "[Epoch 1/121, Batch 11/143] [Losses: x 0.053061, y 0.059495, w 0.071315, h 0.056658, conf 0.136718, cls 0.627339, total 1.004585, recall: 0.62222, precision: 0.03250]\n",
      "[Epoch 1/121, Batch 12/143] [Losses: x 0.071106, y 0.060923, w 0.091344, h 0.039214, conf 0.169764, cls 0.628923, total 1.061274, recall: 0.63768, precision: 0.05559]\n",
      "[Epoch 1/121, Batch 13/143] [Losses: x 0.047328, y 0.069366, w 0.099326, h 0.046957, conf 0.130924, cls 0.604225, total 0.998126, recall: 0.76923, precision: 0.04472]\n",
      "[Epoch 1/121, Batch 14/143] [Losses: x 0.043565, y 0.054630, w 0.087490, h 0.082064, conf 0.138593, cls 0.648941, total 1.055283, recall: 0.58333, precision: 0.04692]\n",
      "[Epoch 1/121, Batch 15/143] [Losses: x 0.029268, y 0.058739, w 0.084985, h 0.052859, conf 0.134707, cls 0.653778, total 1.014334, recall: 0.61111, precision: 0.04216]\n",
      "[Epoch 1/121, Batch 16/143] [Losses: x 0.053644, y 0.050935, w 0.057873, h 0.040087, conf 0.132581, cls 0.649243, total 0.984362, recall: 0.51667, precision: 0.04119]\n",
      "[Epoch 1/121, Batch 17/143] [Losses: x 0.039206, y 0.060648, w 0.057389, h 0.052811, conf 0.148037, cls 0.643912, total 1.002003, recall: 0.66667, precision: 0.04862]\n",
      "[Epoch 1/121, Batch 18/143] [Losses: x 0.039356, y 0.073582, w 0.075722, h 0.037782, conf 0.121993, cls 0.644987, total 0.993423, recall: 0.66667, precision: 0.04538]\n",
      "[Epoch 1/121, Batch 19/143] [Losses: x 0.036870, y 0.058293, w 0.036652, h 0.052236, conf 0.143521, cls 0.630366, total 0.957939, recall: 0.71212, precision: 0.06276]\n",
      "[Epoch 1/121, Batch 20/143] [Losses: x 0.053632, y 0.063197, w 0.055200, h 0.052459, conf 0.123927, cls 0.615924, total 0.964340, recall: 0.71795, precision: 0.04064]\n",
      "[Epoch 1/121, Batch 21/143] [Losses: x 0.077278, y 0.082654, w 0.053905, h 0.050784, conf 0.163036, cls 0.665072, total 1.092728, recall: 0.62162, precision: 0.07411]\n",
      "[Epoch 1/121, Batch 22/143] [Losses: x 0.059136, y 0.059262, w 0.067551, h 0.032663, conf 0.122438, cls 0.626051, total 0.967101, recall: 0.71429, precision: 0.06136]\n",
      "[Epoch 1/121, Batch 23/143] [Losses: x 0.041257, y 0.027523, w 0.056296, h 0.042234, conf 0.112911, cls 0.638190, total 0.918411, recall: 0.64103, precision: 0.04217]\n",
      "[Epoch 1/121, Batch 24/143] [Losses: x 0.031079, y 0.037049, w 0.065539, h 0.057734, conf 0.115089, cls 0.603644, total 0.910134, recall: 0.77778, precision: 0.03652]\n",
      "[Epoch 1/121, Batch 25/143] [Losses: x 0.032139, y 0.029410, w 0.033210, h 0.038137, conf 0.241104, cls 0.646027, total 1.020027, recall: 0.66667, precision: 0.06209]\n",
      "[Epoch 1/121, Batch 26/143] [Losses: x 0.040181, y 0.048118, w 0.058587, h 0.035809, conf 0.133355, cls 0.634371, total 0.950420, recall: 0.62500, precision: 0.04855]\n",
      "[Epoch 1/121, Batch 27/143] [Losses: x 0.053197, y 0.053799, w 0.053469, h 0.064405, conf 0.131590, cls 0.631691, total 0.988152, recall: 0.66667, precision: 0.07143]\n",
      "[Epoch 1/121, Batch 28/143] [Losses: x 0.054966, y 0.051716, w 0.059565, h 0.056860, conf 0.097015, cls 0.642121, total 0.962242, recall: 0.62500, precision: 0.04642]\n",
      "[Epoch 1/121, Batch 29/143] [Losses: x 0.057680, y 0.046668, w 0.040638, h 0.058293, conf 0.144203, cls 0.672857, total 1.020338, recall: 0.54321, precision: 0.05883]\n",
      "[Epoch 1/121, Batch 30/143] [Losses: x 0.042918, y 0.040558, w 0.067537, h 0.053000, conf 0.086940, cls 0.650205, total 0.941159, recall: 0.76190, precision: 0.05791]\n",
      "[Epoch 1/121, Batch 31/143] [Losses: x 0.056308, y 0.048005, w 0.062180, h 0.046507, conf 0.121970, cls 0.626954, total 0.961924, recall: 0.71111, precision: 0.07122]\n",
      "[Epoch 1/121, Batch 32/143] [Losses: x 0.056552, y 0.037748, w 0.068383, h 0.032537, conf 0.148331, cls 0.631412, total 0.974963, recall: 0.65079, precision: 0.05735]\n",
      "[Epoch 1/121, Batch 33/143] [Losses: x 0.039171, y 0.057981, w 0.073931, h 0.048934, conf 0.136843, cls 0.649168, total 1.006028, recall: 0.72727, precision: 0.08240]\n",
      "[Epoch 1/121, Batch 34/143] [Losses: x 0.042244, y 0.057267, w 0.077660, h 0.064097, conf 0.133486, cls 0.651215, total 1.025970, recall: 0.57895, precision: 0.04632]\n",
      "[Epoch 1/121, Batch 35/143] [Losses: x 0.049155, y 0.057091, w 0.044897, h 0.030748, conf 0.141165, cls 0.627944, total 0.950999, recall: 0.69048, precision: 0.06814]\n",
      "[Epoch 1/121, Batch 36/143] [Losses: x 0.059766, y 0.045025, w 0.061022, h 0.087329, conf 0.117762, cls 0.622093, total 0.992997, recall: 0.65333, precision: 0.06241]\n",
      "[Epoch 1/121, Batch 37/143] [Losses: x 0.046898, y 0.038500, w 0.046378, h 0.037613, conf 0.129265, cls 0.620407, total 0.919061, recall: 0.68182, precision: 0.05550]\n",
      "[Epoch 1/121, Batch 38/143] [Losses: x 0.054907, y 0.064300, w 0.055951, h 0.065323, conf 0.130268, cls 0.651874, total 1.022622, recall: 0.52778, precision: 0.04812]\n",
      "[Epoch 1/121, Batch 39/143] [Losses: x 0.046399, y 0.035993, w 0.099012, h 0.066616, conf 0.152822, cls 0.654367, total 1.055209, recall: 0.59091, precision: 0.06476]\n",
      "[Epoch 1/121, Batch 40/143] [Losses: x 0.034088, y 0.058268, w 0.069949, h 0.057141, conf 0.192704, cls 0.638212, total 1.050363, recall: 0.67901, precision: 0.07698]\n",
      "[Epoch 1/121, Batch 41/143] [Losses: x 0.081153, y 0.071747, w 0.082480, h 0.061900, conf 0.129151, cls 0.673503, total 1.099935, recall: 0.53846, precision: 0.07547]\n",
      "[Epoch 1/121, Batch 42/143] [Losses: x 0.039019, y 0.031668, w 0.052259, h 0.034180, conf 0.100537, cls 0.608953, total 0.866615, recall: 0.55556, precision: 0.04694]\n",
      "[Epoch 1/121, Batch 43/143] [Losses: x 0.044661, y 0.033932, w 0.066910, h 0.040029, conf 0.169359, cls 0.621056, total 0.975947, recall: 0.79630, precision: 0.06699]\n",
      "[Epoch 1/121, Batch 44/143] [Losses: x 0.037194, y 0.033498, w 0.047664, h 0.048775, conf 0.256635, cls 0.636884, total 1.060650, recall: 0.66667, precision: 0.04992]\n",
      "[Epoch 1/121, Batch 45/143] [Losses: x 0.034419, y 0.037230, w 0.063767, h 0.058815, conf 0.144648, cls 0.656368, total 0.995248, recall: 0.56944, precision: 0.04615]\n",
      "[Epoch 1/121, Batch 46/143] [Losses: x 0.039082, y 0.050361, w 0.041456, h 0.038412, conf 0.166216, cls 0.641798, total 0.977326, recall: 0.60417, precision: 0.06142]\n",
      "[Epoch 1/121, Batch 47/143] [Losses: x 0.047456, y 0.046818, w 0.102654, h 0.092008, conf 0.127986, cls 0.667564, total 1.084485, recall: 0.65278, precision: 0.06118]\n",
      "[Epoch 1/121, Batch 48/143] [Losses: x 0.039016, y 0.046889, w 0.045177, h 0.035841, conf 0.140368, cls 0.640611, total 0.947902, recall: 0.71429, precision: 0.03963]\n",
      "[Epoch 1/121, Batch 49/143] [Losses: x 0.039743, y 0.038382, w 0.038902, h 0.029680, conf 0.126187, cls 0.647775, total 0.920669, recall: 0.49123, precision: 0.04430]\n",
      "[Epoch 1/121, Batch 50/143] [Losses: x 0.040333, y 0.032851, w 0.058417, h 0.052938, conf 0.138744, cls 0.627755, total 0.951038, recall: 0.73333, precision: 0.04695]\n",
      "[Epoch 1/121, Batch 51/143] [Losses: x 0.092605, y 0.047658, w 0.048040, h 0.029037, conf 0.106614, cls 0.622958, total 0.946912, recall: 0.69444, precision: 0.04393]\n",
      "[Epoch 1/121, Batch 52/143] [Losses: x 0.043045, y 0.028193, w 0.058866, h 0.050412, conf 0.128507, cls 0.649001, total 0.958026, recall: 0.57895, precision: 0.04327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/121, Batch 53/143] [Losses: x 0.066640, y 0.052206, w 0.097015, h 0.062199, conf 0.131133, cls 0.662439, total 1.071633, recall: 0.54902, precision: 0.03146]\n",
      "[Epoch 1/121, Batch 54/143] [Losses: x 0.050862, y 0.057422, w 0.068483, h 0.054679, conf 0.131635, cls 0.637399, total 1.000480, recall: 0.64815, precision: 0.05413]\n",
      "[Epoch 1/121, Batch 55/143] [Losses: x 0.058952, y 0.028412, w 0.061784, h 0.060081, conf 0.123919, cls 0.635500, total 0.968647, recall: 0.64286, precision: 0.03729]\n",
      "[Epoch 1/121, Batch 56/143] [Losses: x 0.050502, y 0.040286, w 0.066804, h 0.082520, conf 0.166472, cls 0.678441, total 1.085025, recall: 0.61458, precision: 0.06041]\n",
      "[Epoch 1/121, Batch 57/143] [Losses: x 0.040538, y 0.036069, w 0.038979, h 0.042691, conf 0.142695, cls 0.616898, total 0.917871, recall: 0.69231, precision: 0.04264]\n",
      "[Epoch 1/121, Batch 58/143] [Losses: x 0.053137, y 0.052026, w 0.046896, h 0.042323, conf 0.149980, cls 0.655251, total 0.999613, recall: 0.65517, precision: 0.06188]\n",
      "[Epoch 1/121, Batch 59/143] [Losses: x 0.035992, y 0.048546, w 0.075236, h 0.036241, conf 0.105738, cls 0.607132, total 0.908884, recall: 0.70833, precision: 0.05051]\n",
      "[Epoch 1/121, Batch 60/143] [Losses: x 0.057274, y 0.042483, w 0.047928, h 0.056863, conf 0.128984, cls 0.621942, total 0.955474, recall: 0.63492, precision: 0.04829]\n",
      "[Epoch 1/121, Batch 61/143] [Losses: x 0.031564, y 0.038074, w 0.076276, h 0.065630, conf 0.109971, cls 0.612117, total 0.933632, recall: 0.74510, precision: 0.05451]\n",
      "[Epoch 1/121, Batch 62/143] [Losses: x 0.037924, y 0.042485, w 0.104116, h 0.030019, conf 0.141203, cls 0.640221, total 0.995967, recall: 0.62500, precision: 0.04889]\n",
      "[Epoch 1/121, Batch 63/143] [Losses: x 0.030207, y 0.041917, w 0.043030, h 0.042655, conf 0.104689, cls 0.626914, total 0.889412, recall: 0.70588, precision: 0.05746]\n",
      "[Epoch 1/121, Batch 64/143] [Losses: x 0.017869, y 0.033247, w 0.066486, h 0.057483, conf 0.078665, cls 0.605247, total 0.858996, recall: 0.80000, precision: 0.04778]\n",
      "[Epoch 1/121, Batch 65/143] [Losses: x 0.028433, y 0.026058, w 0.051890, h 0.042662, conf 0.084030, cls 0.625984, total 0.859057, recall: 0.52381, precision: 0.03923]\n",
      "[Epoch 1/121, Batch 66/143] [Losses: x 0.077039, y 0.038241, w 0.057917, h 0.041168, conf 0.236313, cls 0.660633, total 1.111311, recall: 0.62319, precision: 0.05433]\n",
      "[Epoch 1/121, Batch 67/143] [Losses: x 0.053718, y 0.043938, w 0.051037, h 0.055421, conf 0.121737, cls 0.619328, total 0.945180, recall: 0.77778, precision: 0.07458]\n",
      "[Epoch 1/121, Batch 68/143] [Losses: x 0.041595, y 0.027063, w 0.040503, h 0.038872, conf 0.098200, cls 0.615244, total 0.861477, recall: 0.73684, precision: 0.07435]\n",
      "[Epoch 1/121, Batch 69/143] [Losses: x 0.021502, y 0.025410, w 0.038020, h 0.044389, conf 0.085019, cls 0.650175, total 0.864514, recall: 0.66667, precision: 0.04235]\n",
      "[Epoch 1/121, Batch 70/143] [Losses: x 0.055208, y 0.048021, w 0.059779, h 0.047029, conf 0.140309, cls 0.660570, total 1.010916, recall: 0.60417, precision: 0.07184]\n",
      "[Epoch 1/121, Batch 71/143] [Losses: x 0.048465, y 0.030404, w 0.044140, h 0.032982, conf 0.124637, cls 0.638235, total 0.918862, recall: 0.66667, precision: 0.05603]\n",
      "[Epoch 1/121, Batch 72/143] [Losses: x 0.030415, y 0.024050, w 0.041110, h 0.035411, conf 0.091183, cls 0.647722, total 0.869891, recall: 0.48718, precision: 0.03468]\n",
      "[Epoch 1/121, Batch 73/143] [Losses: x 0.032412, y 0.034935, w 0.051942, h 0.031406, conf 0.101935, cls 0.656800, total 0.909430, recall: 0.53704, precision: 0.04782]\n",
      "[Epoch 1/121, Batch 74/143] [Losses: x 0.030690, y 0.034365, w 0.058678, h 0.042423, conf 0.127425, cls 0.612256, total 0.905838, recall: 0.66667, precision: 0.05858]\n",
      "[Epoch 1/121, Batch 75/143] [Losses: x 0.022284, y 0.035589, w 0.069262, h 0.034133, conf 0.093676, cls 0.644415, total 0.899358, recall: 0.69444, precision: 0.04734]\n",
      "[Epoch 1/121, Batch 76/143] [Losses: x 0.032761, y 0.038728, w 0.108523, h 0.037257, conf 0.078794, cls 0.654305, total 0.950368, recall: 0.61538, precision: 0.04277]\n",
      "[Epoch 1/121, Batch 77/143] [Losses: x 0.033817, y 0.048602, w 0.080355, h 0.046938, conf 0.119455, cls 0.623097, total 0.952263, recall: 0.66667, precision: 0.04764]\n",
      "[Epoch 1/121, Batch 78/143] [Losses: x 0.030815, y 0.029531, w 0.038947, h 0.045388, conf 0.102960, cls 0.653614, total 0.901255, recall: 0.54545, precision: 0.06353]\n",
      "[Epoch 1/121, Batch 79/143] [Losses: x 0.041117, y 0.023776, w 0.030756, h 0.027220, conf 0.091027, cls 0.648639, total 0.862536, recall: 0.77778, precision: 0.06565]\n",
      "[Epoch 1/121, Batch 80/143] [Losses: x 0.046338, y 0.035808, w 0.047070, h 0.028606, conf 0.106571, cls 0.617869, total 0.882262, recall: 0.66667, precision: 0.06165]\n",
      "[Epoch 1/121, Batch 81/143] [Losses: x 0.055738, y 0.030605, w 0.049840, h 0.037500, conf 0.120245, cls 0.650324, total 0.944251, recall: 0.52688, precision: 0.05951]\n",
      "[Epoch 1/121, Batch 82/143] [Losses: x 0.051546, y 0.049475, w 0.073759, h 0.041833, conf 0.099007, cls 0.670053, total 0.985673, recall: 0.60920, precision: 0.08163]\n",
      "[Epoch 1/121, Batch 83/143] [Losses: x 0.071791, y 0.051606, w 0.067282, h 0.051112, conf 0.123907, cls 0.685057, total 1.050754, recall: 0.59804, precision: 0.07948]\n",
      "[Epoch 1/121, Batch 84/143] [Losses: x 0.051913, y 0.059064, w 0.053943, h 0.042976, conf 0.111497, cls 0.643168, total 0.962561, recall: 0.57895, precision: 0.06667]\n",
      "[Epoch 1/121, Batch 85/143] [Losses: x 0.039376, y 0.039039, w 0.056660, h 0.038874, conf 0.098727, cls 0.606971, total 0.879647, recall: 0.77273, precision: 0.09723]\n",
      "[Epoch 1/121, Batch 86/143] [Losses: x 0.062161, y 0.054040, w 0.056533, h 0.056889, conf 0.115147, cls 0.648218, total 0.992988, recall: 0.56566, precision: 0.07510]\n",
      "[Epoch 1/121, Batch 87/143] [Losses: x 0.036815, y 0.037338, w 0.036829, h 0.041894, conf 0.152066, cls 0.630591, total 0.935533, recall: 0.67901, precision: 0.07618]\n",
      "[Epoch 1/121, Batch 88/143] [Losses: x 0.053441, y 0.036134, w 0.030328, h 0.032076, conf 0.121406, cls 0.627604, total 0.900990, recall: 0.61404, precision: 0.05806]\n",
      "[Epoch 1/121, Batch 89/143] [Losses: x 0.061211, y 0.039402, w 0.051668, h 0.043349, conf 0.141960, cls 0.647302, total 0.984890, recall: 0.60714, precision: 0.08154]\n",
      "[Epoch 1/121, Batch 90/143] [Losses: x 0.042569, y 0.046489, w 0.064710, h 0.039968, conf 0.190337, cls 0.645516, total 1.029589, recall: 0.60000, precision: 0.08373]\n",
      "[Epoch 1/121, Batch 91/143] [Losses: x 0.051166, y 0.047714, w 0.048191, h 0.039197, conf 0.164191, cls 0.649858, total 1.000316, recall: 0.70370, precision: 0.08831]\n",
      "[Epoch 1/121, Batch 92/143] [Losses: x 0.037602, y 0.047607, w 0.060427, h 0.057944, conf 0.088797, cls 0.619720, total 0.912097, recall: 0.56410, precision: 0.04211]\n",
      "[Epoch 1/121, Batch 93/143] [Losses: x 0.032332, y 0.030648, w 0.033988, h 0.047295, conf 0.107140, cls 0.630747, total 0.882151, recall: 0.57576, precision: 0.05122]\n",
      "[Epoch 1/121, Batch 94/143] [Losses: x 0.034255, y 0.039919, w 0.023393, h 0.063460, conf 0.083734, cls 0.614157, total 0.858919, recall: 0.61538, precision: 0.04386]\n",
      "[Epoch 1/121, Batch 95/143] [Losses: x 0.038111, y 0.041078, w 0.053966, h 0.048336, conf 0.120995, cls 0.667206, total 0.969692, recall: 0.58824, precision: 0.07374]\n",
      "[Epoch 1/121, Batch 96/143] [Losses: x 0.056845, y 0.024769, w 0.041302, h 0.054515, conf 0.098863, cls 0.616386, total 0.892679, recall: 0.64286, precision: 0.04884]\n",
      "[Epoch 1/121, Batch 97/143] [Losses: x 0.036918, y 0.041039, w 0.028744, h 0.039874, conf 0.107246, cls 0.622156, total 0.875977, recall: 0.69841, precision: 0.07046]\n",
      "[Epoch 1/121, Batch 98/143] [Losses: x 0.031272, y 0.028156, w 0.030938, h 0.041402, conf 0.095831, cls 0.628684, total 0.856283, recall: 0.62963, precision: 0.06589]\n",
      "[Epoch 1/121, Batch 99/143] [Losses: x 0.035165, y 0.029727, w 0.032067, h 0.028945, conf 0.104557, cls 0.614728, total 0.845189, recall: 0.56410, precision: 0.04404]\n",
      "[Epoch 1/121, Batch 100/143] [Losses: x 0.034591, y 0.031686, w 0.029684, h 0.020305, conf 0.116300, cls 0.632818, total 0.865384, recall: 0.52381, precision: 0.05543]\n",
      "[Epoch 1/121, Batch 101/143] [Losses: x 0.037930, y 0.031979, w 0.033007, h 0.049956, conf 0.104038, cls 0.650378, total 0.907289, recall: 0.64198, precision: 0.07648]\n",
      "[Epoch 1/121, Batch 102/143] [Losses: x 0.026964, y 0.024909, w 0.032955, h 0.025579, conf 0.137878, cls 0.656631, total 0.904916, recall: 0.61667, precision: 0.05969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/121, Batch 103/143] [Losses: x 0.026366, y 0.025470, w 0.039787, h 0.044242, conf 0.094506, cls 0.633277, total 0.863648, recall: 0.56250, precision: 0.04665]\n",
      "[Epoch 1/121, Batch 104/143] [Losses: x 0.040507, y 0.033888, w 0.027150, h 0.038958, conf 0.096584, cls 0.598747, total 0.835835, recall: 0.61111, precision: 0.03759]\n",
      "[Epoch 1/121, Batch 105/143] [Losses: x 0.029055, y 0.031878, w 0.038591, h 0.053095, conf 0.090888, cls 0.635024, total 0.878532, recall: 0.66667, precision: 0.04760]\n",
      "[Epoch 1/121, Batch 106/143] [Losses: x 0.045998, y 0.045863, w 0.042586, h 0.040930, conf 0.108590, cls 0.630327, total 0.914293, recall: 0.61905, precision: 0.06310]\n",
      "[Epoch 1/121, Batch 107/143] [Losses: x 0.027637, y 0.034319, w 0.037147, h 0.020157, conf 0.095138, cls 0.666471, total 0.880869, recall: 0.57407, precision: 0.05633]\n",
      "[Epoch 1/121, Batch 108/143] [Losses: x 0.041427, y 0.039005, w 0.045387, h 0.037992, conf 0.175924, cls 0.696960, total 1.036694, recall: 0.46914, precision: 0.05816]\n",
      "[Epoch 1/121, Batch 109/143] [Losses: x 0.035811, y 0.031248, w 0.062192, h 0.040077, conf 0.108453, cls 0.647583, total 0.925364, recall: 0.54167, precision: 0.06927]\n",
      "[Epoch 1/121, Batch 110/143] [Losses: x 0.023984, y 0.047273, w 0.039686, h 0.050851, conf 0.121451, cls 0.651377, total 0.934622, recall: 0.61667, precision: 0.07937]\n",
      "[Epoch 1/121, Batch 111/143] [Losses: x 0.030502, y 0.022450, w 0.042774, h 0.049555, conf 0.102856, cls 0.627336, total 0.875474, recall: 0.61111, precision: 0.04654]\n",
      "[Epoch 1/121, Batch 112/143] [Losses: x 0.057672, y 0.026840, w 0.046294, h 0.059381, conf 0.098706, cls 0.621866, total 0.910758, recall: 0.71429, precision: 0.05533]\n",
      "[Epoch 1/121, Batch 113/143] [Losses: x 0.030565, y 0.021214, w 0.045874, h 0.037665, conf 0.092203, cls 0.621132, total 0.848654, recall: 0.68889, precision: 0.05688]\n",
      "[Epoch 1/121, Batch 114/143] [Losses: x 0.025690, y 0.018337, w 0.045518, h 0.029619, conf 0.095256, cls 0.636467, total 0.850887, recall: 0.70175, precision: 0.08113]\n",
      "[Epoch 1/121, Batch 115/143] [Losses: x 0.035377, y 0.035989, w 0.034425, h 0.019966, conf 0.090628, cls 0.648439, total 0.864825, recall: 0.58333, precision: 0.05139]\n",
      "[Epoch 1/121, Batch 116/143] [Losses: x 0.032711, y 0.040643, w 0.051823, h 0.027972, conf 0.099934, cls 0.659537, total 0.912619, recall: 0.69444, precision: 0.09252]\n",
      "[Epoch 1/121, Batch 117/143] [Losses: x 0.029948, y 0.036278, w 0.086552, h 0.052497, conf 0.127440, cls 0.653313, total 0.986027, recall: 0.57971, precision: 0.07961]\n",
      "[Epoch 1/121, Batch 118/143] [Losses: x 0.044636, y 0.038639, w 0.060414, h 0.053507, conf 0.149259, cls 0.683715, total 1.030170, recall: 0.53763, precision: 0.06271]\n",
      "[Epoch 1/121, Batch 119/143] [Losses: x 0.034276, y 0.018554, w 0.032292, h 0.033716, conf 0.079152, cls 0.636376, total 0.834366, recall: 0.68889, precision: 0.06716]\n",
      "[Epoch 1/121, Batch 120/143] [Losses: x 0.047336, y 0.026034, w 0.036926, h 0.034251, conf 0.073223, cls 0.602006, total 0.819776, recall: 0.73333, precision: 0.08242]\n",
      "[Epoch 1/121, Batch 121/143] [Losses: x 0.051976, y 0.029090, w 0.041613, h 0.041150, conf 0.130566, cls 0.622272, total 0.916666, recall: 0.71795, precision: 0.09288]\n",
      "[Epoch 1/121, Batch 122/143] [Losses: x 0.022519, y 0.024429, w 0.038179, h 0.023642, conf 0.072722, cls 0.609177, total 0.790668, recall: 0.80556, precision: 0.05339]\n",
      "[Epoch 1/121, Batch 123/143] [Losses: x 0.037502, y 0.032710, w 0.035923, h 0.038756, conf 0.098658, cls 0.618377, total 0.861925, recall: 0.66667, precision: 0.07352]\n",
      "[Epoch 1/121, Batch 124/143] [Losses: x 0.029909, y 0.025964, w 0.063980, h 0.026782, conf 0.074082, cls 0.610650, total 0.831366, recall: 0.52381, precision: 0.06333]\n",
      "[Epoch 1/121, Batch 125/143] [Losses: x 0.030856, y 0.037582, w 0.075412, h 0.049983, conf 0.102988, cls 0.614399, total 0.911220, recall: 0.76389, precision: 0.08487]\n",
      "[Epoch 1/121, Batch 126/143] [Losses: x 0.031863, y 0.032346, w 0.061291, h 0.037443, conf 0.099716, cls 0.645515, total 0.908174, recall: 0.57143, precision: 0.07067]\n",
      "[Epoch 1/121, Batch 127/143] [Losses: x 0.021279, y 0.019631, w 0.041999, h 0.022033, conf 0.075389, cls 0.635212, total 0.815542, recall: 0.69048, precision: 0.06279]\n",
      "[Epoch 1/121, Batch 128/143] [Losses: x 0.033717, y 0.031272, w 0.056153, h 0.042725, conf 0.091473, cls 0.654046, total 0.909385, recall: 0.51282, precision: 0.08274]\n",
      "[Epoch 1/121, Batch 129/143] [Losses: x 0.039255, y 0.044606, w 0.097646, h 0.053000, conf 0.161091, cls 0.677400, total 1.072998, recall: 0.45370, precision: 0.06959]\n",
      "[Epoch 1/121, Batch 130/143] [Losses: x 0.048639, y 0.035989, w 0.093089, h 0.023942, conf 0.096208, cls 0.642193, total 0.940059, recall: 0.66667, precision: 0.06080]\n",
      "[Epoch 1/121, Batch 131/143] [Losses: x 0.026909, y 0.024659, w 0.078446, h 0.025136, conf 0.079314, cls 0.611616, total 0.846081, recall: 0.77778, precision: 0.08507]\n",
      "[Epoch 1/121, Batch 132/143] [Losses: x 0.023754, y 0.021189, w 0.061547, h 0.071415, conf 0.113553, cls 0.605112, total 0.896569, recall: 0.63889, precision: 0.07280]\n",
      "[Epoch 1/121, Batch 133/143] [Losses: x 0.027983, y 0.033887, w 0.036806, h 0.030646, conf 0.081374, cls 0.643574, total 0.854270, recall: 0.66667, precision: 0.07957]\n",
      "[Epoch 1/121, Batch 134/143] [Losses: x 0.036970, y 0.020361, w 0.087391, h 0.071763, conf 0.114488, cls 0.623978, total 0.954952, recall: 0.69136, precision: 0.08517]\n",
      "[Epoch 1/121, Batch 135/143] [Losses: x 0.017952, y 0.035291, w 0.042358, h 0.032927, conf 0.073612, cls 0.619223, total 0.821363, recall: 0.68889, precision: 0.05817]\n",
      "[Epoch 1/121, Batch 136/143] [Losses: x 0.053057, y 0.033404, w 0.083556, h 0.037088, conf 0.121606, cls 0.655280, total 0.983992, recall: 0.59420, precision: 0.07704]\n",
      "[Epoch 1/121, Batch 137/143] [Losses: x 0.024640, y 0.029153, w 0.062709, h 0.031428, conf 0.093631, cls 0.625535, total 0.867096, recall: 0.70175, precision: 0.07065]\n",
      "[Epoch 1/121, Batch 138/143] [Losses: x 0.034270, y 0.036216, w 0.063769, h 0.075801, conf 0.088504, cls 0.632691, total 0.931250, recall: 0.71212, precision: 0.07722]\n",
      "[Epoch 1/121, Batch 139/143] [Losses: x 0.038696, y 0.041546, w 0.043004, h 0.050790, conf 0.096485, cls 0.642593, total 0.913113, recall: 0.72222, precision: 0.08184]\n",
      "[Epoch 1/121, Batch 140/143] [Losses: x 0.046059, y 0.034212, w 0.059013, h 0.047160, conf 0.123677, cls 0.626252, total 0.936373, recall: 0.73913, precision: 0.11092]\n",
      "[Epoch 1/121, Batch 141/143] [Losses: x 0.017842, y 0.033925, w 0.055268, h 0.030733, conf 0.085619, cls 0.625050, total 0.848436, recall: 0.72727, precision: 0.08581]\n",
      "[Epoch 1/121, Batch 142/143] [Losses: x 0.021696, y 0.035012, w 0.037113, h 0.015616, conf 0.066728, cls 1.333524, total 1.509689, recall: 0.90476, precision: 0.11541]\n",
      "[Epoch 2/121, Batch 0/143] [Losses: x 0.027129, y 0.040651, w 0.029888, h 0.038760, conf 0.073587, cls 0.668049, total 0.878063, recall: 0.68627, precision: 0.08333]\n",
      "[Epoch 2/121, Batch 1/143] [Losses: x 0.037011, y 0.038223, w 0.055689, h 0.043915, conf 0.091819, cls 0.624740, total 0.891397, recall: 0.66667, precision: 0.07119]\n",
      "[Epoch 2/121, Batch 2/143] [Losses: x 0.027223, y 0.026748, w 0.094397, h 0.059548, conf 0.074122, cls 0.623149, total 0.905186, recall: 0.59524, precision: 0.04977]\n",
      "[Epoch 2/121, Batch 3/143] [Losses: x 0.040604, y 0.036842, w 0.067514, h 0.043243, conf 0.076195, cls 0.630321, total 0.894719, recall: 0.68000, precision: 0.09328]\n",
      "[Epoch 2/121, Batch 4/143] [Losses: x 0.039800, y 0.045054, w 0.053498, h 0.043156, conf 0.094409, cls 0.635966, total 0.911883, recall: 0.61538, precision: 0.08237]\n",
      "[Epoch 2/121, Batch 5/143] [Losses: x 0.027514, y 0.043914, w 0.040148, h 0.061035, conf 0.077697, cls 0.605439, total 0.855746, recall: 0.73684, precision: 0.07915]\n",
      "[Epoch 2/121, Batch 6/143] [Losses: x 0.028846, y 0.050901, w 0.035706, h 0.044430, conf 0.074474, cls 0.636278, total 0.870634, recall: 0.60317, precision: 0.07840]\n",
      "[Epoch 2/121, Batch 7/143] [Losses: x 0.034319, y 0.027406, w 0.055785, h 0.045997, conf 0.061325, cls 0.641678, total 0.866511, recall: 0.61538, precision: 0.05631]\n",
      "[Epoch 2/121, Batch 8/143] [Losses: x 0.035245, y 0.026066, w 0.037998, h 0.041809, conf 0.072756, cls 0.633733, total 0.847608, recall: 0.69444, precision: 0.09660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/121, Batch 9/143] [Losses: x 0.025089, y 0.036816, w 0.029727, h 0.030927, conf 0.061237, cls 0.704395, total 0.888192, recall: 0.44444, precision: 0.04442]\n",
      "[Epoch 2/121, Batch 10/143] [Losses: x 0.030962, y 0.033490, w 0.045827, h 0.029155, conf 0.092140, cls 0.642652, total 0.874227, recall: 0.69333, precision: 0.11157]\n",
      "[Epoch 2/121, Batch 11/143] [Losses: x 0.021586, y 0.031178, w 0.037912, h 0.016933, conf 0.064399, cls 0.618458, total 0.790465, recall: 0.66667, precision: 0.07205]\n",
      "[Epoch 2/121, Batch 12/143] [Losses: x 0.037082, y 0.024018, w 0.050798, h 0.042286, conf 0.064529, cls 0.620681, total 0.839396, recall: 0.65217, precision: 0.11984]\n",
      "[Epoch 2/121, Batch 13/143] [Losses: x 0.030867, y 0.016800, w 0.030768, h 0.042193, conf 0.052775, cls 0.593998, total 0.767401, recall: 0.76923, precision: 0.08771]\n",
      "[Epoch 2/121, Batch 14/143] [Losses: x 0.015802, y 0.037330, w 0.066724, h 0.040911, conf 0.067429, cls 0.632322, total 0.860518, recall: 0.64583, precision: 0.10888]\n",
      "[Epoch 2/121, Batch 15/143] [Losses: x 0.036218, y 0.033232, w 0.037701, h 0.038064, conf 0.047840, cls 0.646321, total 0.839375, recall: 0.57407, precision: 0.09092]\n",
      "[Epoch 2/121, Batch 16/143] [Losses: x 0.039054, y 0.033681, w 0.038108, h 0.030523, conf 0.069085, cls 0.638233, total 0.848684, recall: 0.58333, precision: 0.10252]\n",
      "[Epoch 2/121, Batch 17/143] [Losses: x 0.023695, y 0.030579, w 0.034970, h 0.047625, conf 0.112364, cls 0.630894, total 0.880127, recall: 0.72464, precision: 0.12034]\n",
      "[Epoch 2/121, Batch 18/143] [Losses: x 0.019528, y 0.024247, w 0.044491, h 0.032865, conf 0.129263, cls 0.615942, total 0.866336, recall: 0.75926, precision: 0.10975]\n",
      "[Epoch 2/121, Batch 19/143] [Losses: x 0.029576, y 0.022681, w 0.030502, h 0.031263, conf 0.071765, cls 0.612697, total 0.798485, recall: 0.69697, precision: 0.10493]\n",
      "[Epoch 2/121, Batch 20/143] [Losses: x 0.032548, y 0.024143, w 0.068121, h 0.027961, conf 0.079183, cls 0.604670, total 0.836626, recall: 0.69231, precision: 0.07690]\n",
      "[Epoch 2/121, Batch 21/143] [Losses: x 0.039817, y 0.045157, w 0.051660, h 0.043181, conf 0.124614, cls 0.650734, total 0.955164, recall: 0.63964, precision: 0.12024]\n",
      "[Epoch 2/121, Batch 22/143] [Losses: x 0.019577, y 0.024263, w 0.040261, h 0.031127, conf 0.054798, cls 0.621326, total 0.791352, recall: 0.71429, precision: 0.10553]\n",
      "[Epoch 2/121, Batch 23/143] [Losses: x 0.023889, y 0.026501, w 0.033045, h 0.043758, conf 0.082529, cls 0.623336, total 0.833058, recall: 0.66667, precision: 0.06514]\n",
      "[Epoch 2/121, Batch 24/143] [Losses: x 0.016005, y 0.019659, w 0.037352, h 0.025983, conf 0.066914, cls 0.601438, total 0.767352, recall: 0.72222, precision: 0.05431]\n",
      "[Epoch 2/121, Batch 25/143] [Losses: x 0.022813, y 0.049125, w 0.030728, h 0.026198, conf 0.076232, cls 0.638039, total 0.843135, recall: 0.73684, precision: 0.08196]\n",
      "[Epoch 2/121, Batch 26/143] [Losses: x 0.043671, y 0.027625, w 0.036652, h 0.037792, conf 0.063344, cls 0.625343, total 0.834427, recall: 0.64583, precision: 0.06239]\n",
      "[Epoch 2/121, Batch 27/143] [Losses: x 0.035539, y 0.037149, w 0.036559, h 0.042864, conf 0.109103, cls 0.628609, total 0.889823, recall: 0.63810, precision: 0.09444]\n",
      "[Epoch 2/121, Batch 28/143] [Losses: x 0.040622, y 0.018653, w 0.029676, h 0.032608, conf 0.080216, cls 0.627106, total 0.828882, recall: 0.60417, precision: 0.07387]\n",
      "[Epoch 2/121, Batch 29/143] [Losses: x 0.035829, y 0.038773, w 0.031605, h 0.036739, conf 0.083769, cls 0.663914, total 0.890630, recall: 0.58025, precision: 0.08842]\n",
      "[Epoch 2/121, Batch 30/143] [Losses: x 0.019452, y 0.042911, w 0.087902, h 0.057171, conf 0.065729, cls 0.623347, total 0.896512, recall: 0.78571, precision: 0.08877]\n",
      "[Epoch 2/121, Batch 31/143] [Losses: x 0.041565, y 0.032376, w 0.050619, h 0.036438, conf 0.083362, cls 0.625373, total 0.869732, recall: 0.68889, precision: 0.09575]\n",
      "[Epoch 2/121, Batch 32/143] [Losses: x 0.024118, y 0.027703, w 0.055632, h 0.038403, conf 0.084900, cls 0.623189, total 0.853945, recall: 0.63492, precision: 0.07798]\n",
      "[Epoch 2/121, Batch 33/143] [Losses: x 0.041370, y 0.044944, w 0.063874, h 0.049481, conf 0.122918, cls 0.638650, total 0.961237, recall: 0.72727, precision: 0.11098]\n",
      "[Epoch 2/121, Batch 34/143] [Losses: x 0.025495, y 0.025022, w 0.052700, h 0.036106, conf 0.078275, cls 0.640826, total 0.858424, recall: 0.64912, precision: 0.07483]\n",
      "[Epoch 2/121, Batch 35/143] [Losses: x 0.040029, y 0.037004, w 0.046125, h 0.027141, conf 0.086144, cls 0.624302, total 0.860744, recall: 0.70238, precision: 0.09379]\n",
      "[Epoch 2/121, Batch 36/143] [Losses: x 0.030611, y 0.034495, w 0.047152, h 0.037783, conf 0.078817, cls 0.613437, total 0.842296, recall: 0.66667, precision: 0.09523]\n",
      "[Epoch 2/121, Batch 37/143] [Losses: x 0.028944, y 0.024274, w 0.038080, h 0.033987, conf 0.084156, cls 0.625566, total 0.835007, recall: 0.71212, precision: 0.07749]\n",
      "[Epoch 2/121, Batch 38/143] [Losses: x 0.030412, y 0.027675, w 0.044850, h 0.039643, conf 0.089090, cls 0.655206, total 0.886876, recall: 0.51389, precision: 0.07047]\n",
      "[Epoch 2/121, Batch 39/143] [Losses: x 0.034571, y 0.018791, w 0.068177, h 0.028613, conf 0.079510, cls 0.644458, total 0.874120, recall: 0.63636, precision: 0.09326]\n",
      "[Epoch 2/121, Batch 40/143] [Losses: x 0.029526, y 0.040523, w 0.056846, h 0.037288, conf 0.081687, cls 0.629177, total 0.875047, recall: 0.70370, precision: 0.10630]\n",
      "[Epoch 2/121, Batch 41/143] [Losses: x 0.041536, y 0.037112, w 0.059273, h 0.045071, conf 0.104407, cls 0.661246, total 0.948645, recall: 0.55556, precision: 0.10677]\n",
      "[Epoch 2/121, Batch 42/143] [Losses: x 0.018748, y 0.019102, w 0.036774, h 0.013716, conf 0.055962, cls 0.601953, total 0.746255, recall: 0.66667, precision: 0.08000]\n",
      "[Epoch 2/121, Batch 43/143] [Losses: x 0.024663, y 0.028890, w 0.049507, h 0.025695, conf 0.071654, cls 0.616199, total 0.816608, recall: 0.81481, precision: 0.10117]\n",
      "[Epoch 2/121, Batch 44/143] [Losses: x 0.023675, y 0.028393, w 0.029450, h 0.030844, conf 0.063792, cls 0.625721, total 0.801875, recall: 0.66667, precision: 0.07595]\n",
      "[Epoch 2/121, Batch 45/143] [Losses: x 0.022051, y 0.020390, w 0.046259, h 0.048630, conf 0.088974, cls 0.648989, total 0.875292, recall: 0.50000, precision: 0.06952]\n",
      "[Epoch 2/121, Batch 46/143] [Losses: x 0.034030, y 0.032316, w 0.052470, h 0.031705, conf 0.132336, cls 0.632162, total 0.915018, recall: 0.67708, precision: 0.10223]\n",
      "[Epoch 2/121, Batch 47/143] [Losses: x 0.020922, y 0.024330, w 0.066224, h 0.052141, conf 0.076315, cls 0.658085, total 0.898016, recall: 0.65278, precision: 0.11538]\n",
      "[Epoch 2/121, Batch 48/143] [Losses: x 0.028855, y 0.017440, w 0.043063, h 0.032866, conf 0.084032, cls 0.636345, total 0.842600, recall: 0.78571, precision: 0.06852]\n",
      "[Epoch 2/121, Batch 49/143] [Losses: x 0.023028, y 0.023116, w 0.032789, h 0.026575, conf 0.082628, cls 0.622554, total 0.810689, recall: 0.57895, precision: 0.08860]\n",
      "[Epoch 2/121, Batch 50/143] [Losses: x 0.029062, y 0.025488, w 0.047991, h 0.036482, conf 0.097905, cls 0.618971, total 0.855899, recall: 0.75556, precision: 0.08001]\n",
      "[Epoch 2/121, Batch 51/143] [Losses: x 0.044780, y 0.020237, w 0.041610, h 0.035068, conf 0.063924, cls 0.604069, total 0.809687, recall: 0.69444, precision: 0.07139]\n",
      "[Epoch 2/121, Batch 52/143] [Losses: x 0.031372, y 0.031583, w 0.044895, h 0.022628, conf 0.075444, cls 0.629207, total 0.835129, recall: 0.59649, precision: 0.06601]\n",
      "[Epoch 2/121, Batch 53/143] [Losses: x 0.021195, y 0.017655, w 0.038486, h 0.027010, conf 0.085568, cls 0.629877, total 0.819791, recall: 0.64706, precision: 0.07106]\n",
      "[Epoch 2/121, Batch 54/143] [Losses: x 0.023533, y 0.034016, w 0.032052, h 0.029252, conf 0.090474, cls 0.625421, total 0.834747, recall: 0.70370, precision: 0.08691]\n",
      "[Epoch 2/121, Batch 55/143] [Losses: x 0.017506, y 0.032417, w 0.023981, h 0.028821, conf 0.089524, cls 0.627562, total 0.819811, recall: 0.64286, precision: 0.05781]\n",
      "[Epoch 2/121, Batch 56/143] [Losses: x 0.038720, y 0.028739, w 0.052179, h 0.045452, conf 0.090001, cls 0.667782, total 0.922873, recall: 0.61458, precision: 0.10010]\n",
      "[Epoch 2/121, Batch 57/143] [Losses: x 0.028209, y 0.019219, w 0.020208, h 0.027973, conf 0.077541, cls 0.600131, total 0.773280, recall: 0.79487, precision: 0.06550]\n",
      "[Epoch 2/121, Batch 58/143] [Losses: x 0.049312, y 0.037779, w 0.037951, h 0.037009, conf 0.093647, cls 0.642295, total 0.897994, recall: 0.65517, precision: 0.08511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/121, Batch 59/143] [Losses: x 0.016129, y 0.024452, w 0.046451, h 0.035040, conf 0.071073, cls 0.605493, total 0.798639, recall: 0.70833, precision: 0.07091]\n",
      "[Epoch 2/121, Batch 60/143] [Losses: x 0.029147, y 0.032584, w 0.054813, h 0.036881, conf 0.095439, cls 0.619334, total 0.868199, recall: 0.65079, precision: 0.06391]\n",
      "[Epoch 2/121, Batch 61/143] [Losses: x 0.022749, y 0.024450, w 0.057992, h 0.067135, conf 0.078278, cls 0.607642, total 0.858246, recall: 0.76471, precision: 0.08114]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "from utils.parse_config import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--epochs\", type=int, default=30, help=\"number of epochs\")\n",
    "parser.add_argument(\"--image_folder\", type=str, default=\"data/samples\", help=\"path to dataset\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=16, help=\"size of each image batch\")\n",
    "parser.add_argument(\"--model_config_path\", type=str, default=\"config/yolov3.cfg\", help=\"path to model config file\")\n",
    "parser.add_argument(\"--data_config_path\", type=str, default=\"config/coco.data\", help=\"path to data config file\")\n",
    "parser.add_argument(\"--weights_path\", type=str, default=\"weights/yolov3.weights\", help=\"path to weights file\")\n",
    "parser.add_argument(\"--class_path\", type=str, default=\"data/coco.names\", help=\"path to class label file\")\n",
    "parser.add_argument(\"--conf_thres\", type=float, default=0.8, help=\"object confidence threshold\")\n",
    "parser.add_argument(\"--nms_thres\", type=float, default=0.4, help=\"iou thresshold for non-maximum suppression\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=0, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=416, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--checkpoint_interval\", type=int, default=1, help=\"interval between saving model weights\")\n",
    "parser.add_argument(\n",
    "    \"--checkpoint_dir\", type=str, default=\"checkpoints\", help=\"directory where model checkpoints are saved\"\n",
    ")\n",
    "parser.add_argument(\"--use_cuda\", type=bool, default=True, help=\"whether to use cuda if available\")\n",
    "opt = parser.parse_args(args=['--model_config_path', '/home/dllab/final/yolov3.cfg', '--data_config_path', '/home/dllab/final/clothes.data', '--class_path', '/home/dllab/final/clothes.names', '--checkpoint_interval', '10', '--checkpoint_dir', '/tmp/work', '--epoch', '121', '--batch_size', '7', '--weights_path', '/tmp/work/105.pt'])\n",
    "print(opt)\n",
    "\n",
    "cuda = torch.cuda.is_available() and opt.use_cuda\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "classes = load_classes(opt.class_path)\n",
    "\n",
    "# Get data configuration\n",
    "data_config = parse_data_config(opt.data_config_path)\n",
    "train_path = data_config[\"train\"]\n",
    "\n",
    "# Get hyper parameters\n",
    "hyperparams = parse_model_config(opt.model_config_path)[0]\n",
    "learning_rate = float(hyperparams[\"learning_rate\"])\n",
    "momentum = float(hyperparams[\"momentum\"])\n",
    "decay = float(hyperparams[\"decay\"])\n",
    "burn_in = int(hyperparams[\"burn_in\"])\n",
    "\n",
    "# Initiate model\n",
    "model = Darknet(opt.model_config_path)\n",
    "# model.load_weights(opt.weights_path)\n",
    "model = torch.load(opt.weights_path)        #use this to load\n",
    "#model.apply(weights_init_normal)\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Get dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    ListDataset(train_path), batch_size=opt.batch_size, shuffle=False, num_workers=opt.n_cpu\n",
    ")\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    for batch_i, (_, imgs, targets) in enumerate(dataloader):\n",
    "        imgs = Variable(imgs.type(Tensor))\n",
    "        targets = Variable(targets.type(Tensor), requires_grad=False)\n",
    "        \n",
    "        imgs = imgs.to('cuda') \n",
    "        targets = targets.to('cuda') \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = model(imgs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d, Batch %d/%d] [Losses: x %f, y %f, w %f, h %f, conf %f, cls %f, total %f, recall: %.5f, precision: %.5f]\"\n",
    "            % (\n",
    "                epoch,\n",
    "                opt.epochs,\n",
    "                batch_i,\n",
    "                len(dataloader),\n",
    "                model.losses[\"x\"],\n",
    "                model.losses[\"y\"],\n",
    "                model.losses[\"w\"],\n",
    "                model.losses[\"h\"],\n",
    "                model.losses[\"conf\"],\n",
    "                model.losses[\"cls\"],\n",
    "                loss.item(),\n",
    "                model.losses[\"recall\"],\n",
    "                model.losses[\"precision\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model.seen += imgs.size(0)\n",
    "\n",
    "    if epoch % opt.checkpoint_interval == 0:\n",
    "        #model.save_weights(\"%s/%d.weights\" % (opt.checkpoint_dir, epoch))\n",
    "        torch.save(model, \"%s/%d.pt\" % (opt.checkpoint_dir, epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
